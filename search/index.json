[{"content":"Creation of Docker images from a file/folder It seemed to be an easy task to just use Docker Images as file archives, since you could simply create an image with a command like\nsudo tar cv buildcache_persist |docker import - \u0026#34;${CICACHETAG}\u0026#34; \u0026amp;\u0026amp; docker push \u0026#34;${CICACHETAG}\u0026#34; ( in our examples we assume that we want to save/restore the folder buildcache_persist )\nExtraction ( and the trouble ) But the extraction was a bit more complicated, dealing with tar archives should be not too complicated , but it did\u0026rsquo;t instantly work on all machines..\n( Do not use below code , it worked only on 1 out of 3 systems)\necho \u0026#34;REMOVING AND GETTING ${CICACHETAG} AGAIN ( MERGE )\u0026#34; docker rmi ${CICACHETAG} docker pull ${CICACHETAG} \u0026amp;\u0026amp; ( cd /tmp/;docker save ${CICACHETAG} \u0026gt; /tmp/.importCI ; tar xvf /tmp/.importCI --to-stdout $(tar tf /tmp/.importCI|grep layer.tar) |tar xv rm /tmp/.importCI ) echo \u0026#34;SAVING ${CICACHETAG}\u0026#34; In fact Murphys Law kicked in \u0026ldquo;again\u0026rdquo;, since everything went well in \u0026ldquo;real machines\u0026rdquo; but CI-Runners failed with \u0026ldquo;famous\u0026rdquo; error:\ntar: invalid tar header checksum The internetz , or better Stack Overflow a.k.a. Crap Overload had some half-knowledge + false-positive answer again Once more the Stackoverflow thread was merely helpful ,\nsince the answer closest to the simplest solution is lowest-voted, AND STILL FULL OF FAILS ( that could be easily checked on a command line instead of sh*tloading half-knowledge)\nBut just for the lulz ( and not being downvoted on swag overload ) ,\nhere\u0026rsquo;s the wipe-*ss part for that answer line-by-line:\nStackOverflow answer of Konstantin P. Truth id=$(docker create image:tag) does not work without command set for e.g. FROM scratch containers docker export $id -o image.tar docker export accepts only ONE argument (\u0026hellip;) docker rm $id better quote \u0026quot;$id\u0026quot; or curly-bracket ${id} UNMENTIONED The suggested solution extracts EVERYTHING including /etc/ /dev/ and so on .. The one-line Solution : extraction of specific files of a docker container without single layer extraction To narrow it down :\nonly extraction of specific files is possible ( here only buildcache_persist) there is no need to bloat up the filesystem with temporary tar files Here we go :\ndocker export $(docker create --name cicache docker.io/my-org/my-cicache-image:example-tag /bin/false ) |tar xv buildcache_persist ;docker rm cicache This command wil extract only the folder buildcache_persist into the current directory\nHappy Coding\u0026hellip;\n","date":"2023-03-22T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_03_22_exporting_all_layers_of_docker_images_with_one_command/imgs/docker-extract-fail.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_03_22_exporting_all_layers_of_docker_images_with_one_command/","title":"Exporting all layers of docker images with one command"},{"content":"===\nGithub actions may be a source of luck and fun or pain. The moments when it does not accept your workflow file are the the worst amongs them.\nHelp is on the way Firstly , there is GitHub Action-LINT , so there is no more push-check-push-check necessary anymore as it works instant in your browser. In the current case, the indent of the beging of the words need to be matched , so here is a line-by-line comparison\nWrong Correct Action-LINT shows a dot next to the line , since run: is errnously placed one whitespace too much to the right. This often happens when the colons ( : ) are placed directly over each other Action LINT does not complain when run: and name: have the proper indentation and the first characters are directly above each other You are using gitlab ? Cool for you ,\nthere is a GitLab-CI LINTER and even a VS-Code Gitlab-CI Validator Happy Coding\n","date":"2023-03-04T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_03_04_github_actions_could_not_parse_as_yaml_mapping_values_are_not_allowed_in_this_context/imgs/github-actionlint.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_03_04_github_actions_could_not_parse_as_yaml_mapping_values_are_not_allowed_in_this_context/","title":"Github Actions could not parse as YAML: mapping values are not allowed in this context"},{"content":"The Question: how to get MYSQL rows of last month ? The \u0026ldquo;simple\u0026rdquo; question \u0026ldquo;how do i get MySQL records of previous month\u0026rdquo; unfolded many threads , sometimes even giving false positive answers like:\ntake the difference between now and now-1 month (DO NOT !)\nThe Solution: Two MYSQL timestamps with INTERVAL calculated Ok, not only sometimes false postives are recommended , in fact very often.. , so here we go with a proper example:\nSELECT o.row_a , o.row_b, WHERE row.something = `foo` AND (o.`date_add` \u0026gt;= DATE_FORMAT( CURRENT_DATE - INTERVAL 2 MONTH, \u0026#39;%Y/%m/01\u0026#39; ) ) AND (o.`date_add` \u0026lt; DATE_FORMAT( CURRENT_DATE - INTERVAL 1 MONTH, \u0026#39;%Y/%m/01\u0026#39; ) ) ( only the part from AND on is important to us )\nTo get other months ( or days or years), just modify the INTERVAL 1 MONTH and the second AND statement\nADDENDUM: current month to have \u0026ldquo;nearly the same\u0026rdquo; query for the current month, do\nAND (o.`date_add` \u0026gt;= DATE_FORMAT( CURRENT_DATE, \u0026#39;%Y/%m/01\u0026#39; ) ) AND (o.`date_add` \u0026lt; DATE_FORMAT( CURRENT_DATE + INTERVAL 1 MONTH, \u0026#39;%Y/%m/01\u0026#39; ) ) ","date":"2023-02-03T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_02_03_mysql_records_of_previous_month/imgs/sql-last-month.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_02_03_mysql_records_of_previous_month/","title":"MYSQL records of previous month"},{"content":"Stackoverflow - you want help ? you get downvotes Somehow people might be attracted by Stack Overflow ,\nmaybe because it\u0026rsquo;s mostly top-ranked by Search Engines, maybe because sometimes it really helps , maybe it keeps people in business that should better do stuff without brain-usage or something where they cannot harm people. But over the years it has become a dirt-pool that is quicker in instant-downvoting and duplicate-flagging than answering.\nMaybe that is what happens when platforms tend to be \u0026ldquo;up/down-vote\u0026rdquo;-style places full of Mr./Mrs.-always-right \u0026hellip;\npeople that post and are downvoted just because of \u0026ldquo;how the answer was \u0026quot; just leave or don\u0026rsquo;t post anymore, leaving the self-confirming \u0026ldquo;crowd\u0026rdquo; to play their toxic games\nin fact the knowledge collected is turned into $$$ by StackOverflow\nThere is a youtube Video that has some painful examples of what is going on over there , stories where people are rewarded to remove their questions (WTF!)\nIn the description there is a very true statement:\nThe Stack Overflow culture needs to be fixed. The overall gatekeeping \u0026amp; elitism in computer science \u0026amp; programming - as a whole - needs to be fixed. I just see it more on Stack Overflow than anywhere else .\nthe internet is full of threads that ask why a bunch of bullies is dominating on SO\nAnd to sum it up there is a reddit that says it all , so here are some quotes ( of more than 1 user ) from that thread:\nIn return for my technical question, I get what amounts to a colonoscopy, by what appear to be 14 year old \u0026ldquo;engineers\u0026rdquo;, who racked up internet points asserting wrong information with brazen confidence.\nWhy is everyone responding in underhanded, condescending tone, under a thin veil of technical clarification?\nWhy is it that people who don\u0026rsquo;t know the answer, nor care to even understand the question, need to comment, then upvote their incorrect comments, all meanwhile downvoting my question?\n.. asking a question on SO is equivalent to giving up whatever dignity you have, or be downvoted for no logical reason.\nSO has always had a problem with toxicity. I think the main reason for this is that it\u0026rsquo;s not actually a Q\u0026amp;A platform. It\u0026rsquo;s a wiki under the guise of a Q\u0026amp;A platform. This explains why people can edit your posts and why ++SO explicitly encourages users to post questions that they already have the answer to**.\nSO doesn\u0026rsquo;t want people to post questions asking for help. They want people to create Q\u0026amp;A-style wiki pages to add to their curated collection of knowledge. If your question doesn\u0026rsquo;t have a good answer of general use to the populous, then it\u0026rsquo;ll be downvoted and closed because it\u0026rsquo;s not useful to them.\nUnfortunately, people innocently try to get help on the site and are subsequently berated and their questions torn apart. SO has tried to address this issue, but it seems that they haven\u0026rsquo;t made any progress. The first rule of SO is NEVER EVER ask questions on it. It\u0026rsquo;ll get down voted and marked as duplicate immediately. It\u0026rsquo;s a great reference. Absolutely terrible source of help.\nA reddit has some user-horror-stories and a lot of criticism about the self-righteous moderators and that they act as if they were the north-korean authorities, here are some excerpts:\nStackoverflow lives from the contribution of thousands contributors, but is controlled by a small band of moderators who have dictatorship like powers \u0026hellip; Of course, it is good that Stackoverflow tries to enforce a certain level of quality for its content, but having this \u0026ldquo;police\u0026rdquo; punishing others leads to the same problem like any other police has: They feel they are omnipotent and always right, even if they are wrong. I wish Stackoverflow would be more supporting of their content provider and help them to improve their contribution instead of removing content with wrong justifications and no easy way to challenge that .\nOne tool these moderators like to use to suppress a discussion is to mark a question as duplicate, which means the question/answers get closed, no further discussion is possible. They just pretend that a many year old question sounds similar . The worst example I have seen: A question asked why he gets a null reference in a specific WPF situation. The question got marked as duplicate, because someone had posted 100 reasons why a null reference can happen, but with zero relevance for WPF. There was a good reason why the null reference exception happened in this particular situation, but it was no longer possible to add an answer explaining why the problem happen. And normal mortals have no chance to overturn the duplicate decision, for that you need to have a tons of points on Stackoverflow.\n.. problem started when my answer got deleted with the reason \u0026quot; Code plagiarised without attribution\u0026rdquo;, which was wrong in my opinion . Since my original answer got deleted, you cannot see in that link, that\u0026rsquo;s how censorship works on Stackoverflow. I wrote all the content myself, except at the very end where I pasted some WPF source code. I made it clear that this was not my code and where it is coming from\u0026hellip; clearly stated that I could not write this code and that it is WPF source code. How can this be plagiarism ?\nI am using Stackoverflow since many years but I really could not figure out how to appeal this decision. So I tried to raise the issue on Meta: https://meta.stackoverflow.com/questions/416605/how-to-get-an-answer-deleted-by-a-moderator-because-of-code-plagiarized-withou. I did this reluctantly due to my earlier experience with self-righteous moderators, who usually react aggressively when anyone dares to mention that there was a problem on Stackoverflow. I wonder if they feel personally questioned and go into defense/attack mode automatically \u0026hellip; got there comments like \u0026ldquo;You don\u0026rsquo;t know how to quote and cite your sources when writing any professional document? I find that hard to believe.\u0026rdquo; Well, the truth is that I have never written a professional document citing sources. As it is common on Meta, many commenters do not consider if the case presented has any merit (i.e. I did write in my answer that it is not my code and where I got it from). Instead they like to attack the person who dares to question their actions\u0026hellip; To suppress any further discussion, the moderators used their preferred weapon and marked my Meta post as duplicate, even the other question had completely different circumstances.\nSince they didn\u0026rsquo;t like me raising my question on Meta, they also marked my original question as duplicate. Please note that my question had gone already through a review process and was accepted as proper. Only after I raised it on Meta my original question was closed because of \u0026ldquo;This question needs details or clarity\u0026rdquo;. Again, no easy option to appeal the decision. The only action they allow is that I change my question.\nIn the replies, users have more horrific stories:\n.. once asked a question that took hours to write and referenced 5 different approaches to the problem, and all I got was a downvote without explanation.\nstack overflow has at this point deleted as much useful content as it currently contains\u0026hellip; there were always attitude issues amongst the power users, I wouldn\u0026rsquo;t expect anything less, but when they started getting militant about the definition of subjective and combining loosely related topics as duplicate then later *deleting the question the defined as the original as low quality it started to go downhill pretty fast\nSO has become a place where dictatorship is rife, people are unfriendly and there is too much moderation going on.\nStackOverflow has become a slightly less spammy version of Experts Exchange. It\u0026rsquo;s woefully out of date on most things, gives bad and/or conflicting advice on everything else, and generally has become a useless pile of junk. And most of the reason is what you\u0026rsquo;ve described here. The moderator fiefdoms result in petty turf wars and bad comments rise to the top because of political reasons rather than technical ones.\n\u0026ldquo;Someone read your answer\u0026rdquo;, no they did not read it, they just posted competitive answer and after they realized they need a little bit more reputation (for what?!) and my answer is already upvoted (more important to them then to me), they started plagiarism story. Couple hour later, moderator that also did not check ANYTHING (answer, profile, links\u0026hellip;) deleted my post. There is no reason for any kind of \u0026ldquo;we are just trying to protect our company\u0026rdquo; action, but on the contrary: people are decreasing SO reputation because they need just to distinguish themselves, not to help people.\nFyi Stack overflow is really old \u0026hellip; Is still uses Windows Server and MSSQL\nOn Quora .. different place , same story\nTo also cite the \u0026ldquo;highlights\u0026rdquo;(dark spots) of SO from there:\nIt’s the dumbest web-site I’ve ever seen. They should help people but they kept closing my questions for no reason, even banned me from asking more. I am asking BECAUSE I am not a pro. I always tried to be concise and clear, their stupid bots just closed many of my questions.\nthe voting system on Stack Overflow is that it penalizes users. It only takes a few negative votes to get you banned from asking questions, taking part on the platform. In my experience, rarely do downvotes get removed from questions that have been improved through editing. Even \u0026ldquo;deleting\u0026rdquo; questions will not remove their negative score on one\u0026rsquo;s account. \u0026hellip; ** the strict gamification** of Stackoverflow, turning users into winners and losers, creates an overall unwelcoming, precarious attitude towards beginner programmers\nit’s sh*t, and I will use the word totalitarian, Stack Overflow (regarding its coding forums side) is a totalitarian place, the totalitarianism is first handled by the people who run SO.\nIn the mentioned Quora thread \u0026hellip;.\nthe Quora Question Details Bot seems to have a good sense of humour, since it replies to the Question\nWhat is bad about Stack Overflow?\nwith the balls-of-steel answer\n...if you're using their service.\nFinal statement In the end there is no need to delete your Crap-Overload account, just don\u0026rsquo;t ask if you don\u0026rsquo;t want to loose your dignity , there is even an answer how to log out :D But to be honest : Windows Server and MSSQL Stack in 2022 ?\nThey could just ask on their platform why and how to not do that .. Basically when reading CVE\u0026rsquo;s on a regular basis , nobody should put personal data there\u0026hellip;\n","date":"2023-02-02T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_02_02_shittification_of_the_internetz-the_toxic_thingy_stack_overflow_became_and_why_it_is_so_annoying_to_even_ask_on_crap_overload/imgs/so_keyboard_Nisarg_Shah.twitter.Nisarg259.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2023_02_02_shittification_of_the_internetz-the_toxic_thingy_stack_overflow_became_and_why_it_is_so_annoying_to_even_ask_on_crap_overload/","title":"Shittification of the internetz - The toxic thingy Stack Overflow became and why it is so annoying to even ask on Crap Overload"},{"content":"Note In \u0026ldquo;earlier\u0026rdquo; days you could easily add missing GPG keys with a command like:\napt-key adv --keyserver keyserver.ubuntu.com --recv-keys D68FA50FEA312927\nBUT most modern distributions will tell you\napt-key is deprecated. manage keyring files in trusted.gpg.d instead So you should stop using it and use gpg directly ,\nyou might export the old keys by issuing apt-key list and then using the last 8 characters like this\nsudo apt-key export 3A798D29 | sudo gpg --dearmour -o /etc/apt/trusted.gpg.d/mysql-key.gpg\nFor external GPG Pubkeys ( new repos e.g. ) from now on add them like this :\nKEYRING=/usr/share/keyrings/yourpackagename.gpg curl -fsSL https://server.lan/key-path-to-download | gpg --dearmor | sudo tee \u0026#34;$KEYRING\u0026#34; \u0026gt;/dev/null Error indicators Obviously apt/apt-get update will output\napt-get update fails with Unknown error executing apt-key ,\nErrors you might face when trying to manually run apt-key look like:\n/usr/bin/apt-key: 710: touch: Too many levels of symbolic links Solutions for failing apt-key Hint: if your system or package registry is heavily damaged , you might manually search for the .deb packages and install them Solution 1: Coreutils reinstallation If you see /usr/bin/touch exists but not /bin/touch,\nInstalling the latter using sudo apt-get install --reinstall coreutils might help.\nSolution 2: GPG reinstallation Your GPG installation might be updated or outdated\nsudo apt reinstall gpg sudo ldconfig $(which /usr/bin/gpg) References info resource 2022-04-28 @ stackoverflow.com → gnupg - W: GPG error: Unknown error executing apt-key - Stack Overflow 2022-03-17 @ unix.stackexchange.com → linux - apt-get gpg error when i try to update - Unix \u0026amp; Linux Stack Exchange 2021-11-15 @ unix.stackexchange.com → apt key - I am suddenly getting \u0026quot; Unknown error executing apt-key\u0026quot; when attempting to update my system - Unix \u0026amp; Linux Stack Exchange ","date":"2022-04-29T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_04_29_apt-get_update_fails_with_unknown_error_executing_apt-key/imgs/apt-key-deprecated.jpg","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_04_29_apt-get_update_fails_with_unknown_error_executing_apt-key/","title":"apt-get update fails with Unknown error executing apt-key"},{"content":"//failed: Code 500 again .. Ocotobercms refuses to load and you might be out of guesees again Let\u0026rsquo;s first review the possible Problems known:\nProblem Measure cache and config not reloaded during deployment issue php artisan config:cache;php artisan cache:clear first when working on pages resources include begin with / you changed all the asset includes under themes/YOURTHEME/partials to NOT begin with slashes like / storage since that confuses many webservers , especially chroot()-ed ones like Plesk resources/views missing you created the empty folder resources/views since it might lead to the open_basedir message .htaccess woes you checked your .htaccess to have a proper RewriteBase and the correct webroot if you set it fixed But the almost \u0026ldquo;beloved\u0026rdquo; open_basedir restriction message pops up again Dowtime hurts and if you did not setup some monitoring you not notice since may be cleared randomly ..\nit is always a good idea to check storage/logs/system.log since your webserver-log does not tell everything and it\u0026rsquo;s log might be cut due to php-fpm, check the file logs or maybe the database as well for potential errors\n//fixed ","date":"2022-01-20T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_21_oh_octobercms_and_the_leading_slash_again/imgs/octoslash.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_21_oh_octobercms_and_the_leading_slash_again/","title":"Oh OctoberCMS and the leading slash again"},{"content":" Many things might have gone wrong\nfailed Synology update upgraded openWRT/friendlywrt changed the place disk restoration from failed root unless you did start your container with \u0026ldquo;--rm\u0026rdquo; and delete it , there is hope ( and even if not you may pull the brake, power off and engage e.g. testdisk )\nSETUP approx. Date Place old-friendlyWRT(openwrt) 2020 /opt/volumes new-friendlyWRT(openwrt) 2020 /opt/docker/volumes/ standard deployment 2021 /var/lib/docker/volumes/ synology VOLUME 2022 /volume1/\\@docker/volumes/ synology BTRFS 2020 /opt/ custom setup **** refer to /etc/docker/daemon.json ","date":"2022-01-18T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_19_restoring_lost_data_from_docker_volumes/imgs/daemon.json.transp-yellow.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_19_restoring_lost_data_from_docker_volumes/","title":"Restoring lost data from Docker volumes"},{"content":"So your previous config might have looked like:\n###### CARDDAV upstream syno_carddav { # The keepalive parameter sets the maximum number of idle keepalive connections # to upstream servers that are preserved in the cache of each worker process. When # this number is exceeded, the least recently used connections are closed. keepalive 50; server w.x.y.z:5008; } The newer DSM-7.0 has the calDAV endpoint https://w.x.y.z:5001/.well-known/carddav However this is not the full story the /.well-known will redirect to /carddav/.web When you call it in the Webinterface you will see : Radicale works!\n![caldav curl](imgs/caldav.png) ","date":"2022-01-10T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_10_synology_dsm_changes_caldav_port/imgs/caldav-transp.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_10_synology_dsm_changes_caldav_port/","title":"Synology DSM changes calDAV port"},{"content":"It is time to build your fonts proxy - now ! Your may ask why ..\nSince Google does not even cache the fonts anymore and it is not GDPR-compliant also because google may track your users at least on the level of a matomo-instance. you can do better.\nWith the simple nuster-nginx combination ( tested on aarch64 and x86_64 ) , one can\nanonymize the IP-Adress anonymize the User-Agent serve custom 404 pages that are also anoymously passed for all requests through that instance. get the nuster-cache-proxy files:\ngit clone ; cd create a .env-File ( like below, change at least the domain and the letsencrypt mail address)\necho \u0026#39; VIRTUAL_PORT=80 VIRTUAL_PROTO=http VIRTUAL_HOST=fonts.your-domain.lan LETSENCRYPT_EMAIL=no@body.lan LETSENCRYPT_HOST=fonts.your-domain.lan CACHED_PATH=/ CACHED_HOST=fonts.gstatic.com COMPOSE_POJECT_NAME=myservicename RETURN_UNAUTH=false ACCESS_LOG=false ##optional REDIRECT_FAVICON=false CACHEMB=512 CACHETIME=90d TIMEOUT=15s HIDECLIENT=true EXPIREHEADER=7d LOCALPORT=65080 NGINX_NETWORK=nginx-proxy CUSTOMFOUROFOUR=https://statuspages.gitlab.io/404 CUSTOMENDPOINTS=/css:fonts.googleapis.com REPLACESTRING=fonts.gstatic.com:fonts.your-domain.lan,fonts.googleapis.com:fonts.fonts.your-domain.lan \u0026#39; \u0026gt; .env create the named network ( docker network create nginx-proxy ) or adjust .env run docker-compose up -d replace the domains fonts.googleapis.com and fonts.gstatic.com to your domain ( in example here fonts.your-domain.lan ) in all your webpages and themes, example result: \u0026lt;link rel=\u0026#34;shortcut icon\u0026#34; href=\u0026#34;favicon.ico\u0026#34;\u0026gt; \u0026lt;link href=\u0026#39;//fonts.mydomain.lan/css?family=Open+Sans:300,400,600,700\u0026#39; rel=\u0026#39;stylesheet\u0026#39; type=\u0026#39;text/css\u0026#39;\u0026gt; \u0026lt;!-- Global CSS --\u0026gt; Use the font-proxy in your Firefox or Chrome with any domain when sufing the web install a header/request changing Plugin ( in ths Example GooReplacer ) Chrome Firefox ( if the gooreplacer does not load /assets/at_alicdn_com/t/font_148784_v4ggb6wrjmkotj4i.woff from the settings page , you may rewrite it as well ) setup a replacement like below (there is a trailing slash at the target url ) ","date":"2022-01-01T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_01_creating_a_gdpr_compliant_google_fonts_proxy/imgs/fontscss.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2022_01_01_creating_a_gdpr_compliant_google_fonts_proxy/","title":"Creating a GDPR compliant google fonts or CDN proxy"},{"content":"Oh no, synology share creation failed .. Trying to create a share ( here with no users) DIRECTLY on the top of your volume with e.g. /usr/syno/sbin/synoshare --add docker-volumes \u0026quot;Docker volumes on diskstation\u0026quot; /volume1/ \u0026quot;\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; 1 0\nWill yield the following error, Error: share create failed.[0x0D00 share_is_acl_share.c:49]\nbut why ? You cannot create shared volumes that are the Volume itself , just append another directory name to your path /usr/syno/sbin/synoshare --add docker-volumes \u0026quot;Docker volumes on diskstation\u0026quot; /volume1/ \u0026quot;myvolume\u0026quot; \u0026quot;\u0026quot; \u0026quot;\u0026quot; 1 0 ","date":"2021-08-23T13:37:42Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_08_23_synology_synoshare_create_error_share_create_failed_0x0d00_share_is_acl_share/imgs/syno.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_08_23_synology_synoshare_create_error_share_create_failed_0x0d00_share_is_acl_share/","title":"Synology synoshare create Error: share create failed.[0x0D00 share_is_acl_share.c:49]"},{"content":" Sometimes restic does not correctly apply the forget policy And that might waste\ntons of space .. computation time during backup \u0026hellip; clarity since terminal goes a bit crazy with 3000+ lines The fix is not so easy\u0026hellip; forgetlist=\u0026#34;\u0026#34;;restic unlock; restic snapshots|grep \u0026#34;[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9] [0-9][0-9]:[0-9][0-9]:[0-9][0-9]\u0026#34;|sed \u0026#39;s/ \\+/ /g\u0026#39;|cut -d\u0026#34; \u0026#34; -f1-3|while read line;do id=${line/ *}; shotdate=$(echo \u0026#34;$line\u0026#34;|cut -d\u0026#34; \u0026#34; -f2,3) ; shotepoch=$(date -u -d \u0026#34;$shotdate\u0026#34; +%s) ; shotagesec=$(($(date -u +%s )-$shotepoch)); echo -n \u0026#34;SNAP: $shotdate ( $shotagesec ) \u0026#34;; [[ $shotagesec -ge $((86400*90)) ]] \u0026amp;\u0026amp; { echo -n \u0026#34;forget $id |\u0026#34; ;forgetlist=\u0026#34;$forgetlist $id\u0026#34; ; echo \u0026#34;$forgetlist\u0026#34; \u0026gt; /dev/shm/.restic_forget_list ; } ; [[ $(echo $forgetlist|wc -w ) -ge 30 ]] \u0026amp;\u0026amp; { restic forget $forgetlist |sed \u0026#39;s/$/|/g\u0026#39; |tr -d \u0026#39;\\n\u0026#39; ;forgetlist=\u0026#34;\u0026#34; ; } ; echo;done; restic forget $forgetlist |sed \u0026#39;s/$/|/g\u0026#39; |tr -d \u0026#39;\\n\u0026#39; ;forgetlist=\u0026#34;\u0026#34; ;time restic prune Oh wow ..\n","date":"2021-08-13T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_08_13_deleting_old_restic_entries/imgs/rst.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_08_13_deleting_old_restic_entries/","title":"Deleting old restic snapshots"},{"content":"So when somebody believes his or her favourite scam site,\ne.g LinkedIn.___ does not index my page\nand they ask op to renew a certificate \u0026hellip; but the only thing known is that docker-nginx-letsencrypt (jwilder) does a renewal for all \u0026ldquo;due\u0026rdquo; certificates ( 21 days or less left )\nit is one of this \u0026ldquo;0 hits on google.com\u0026rdquo; days ..\nuntil now \u0026hellip;\ndocker exec -it nginx-letsencrypt /bin/bash /app/force_renew is your friend in that case ;)\n","date":"2021-03-11T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_03_21_docker_nginx_force_renew_letsencrypt/imgs/le.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_03_21_docker_nginx_force_renew_letsencrypt/","title":"The Google Blackhole: Forced renewal of certificates with nginx-letsencrypt-docker"},{"content":"Since there was no chance , not even adding uptime-robot\u0026rsquo;s TG bot to a a group and sed the start token.\nAnd it came in handy , you could monitor everything also from node.js or other languages.\nWith this method you could basically let everything send Messages to telegram ( although you should not hand out your bot credentials and use some intermediate Message-Router , you can even use node-red or n8n )\nSample Setup Create a new contact ( here we use Alerts since the time is not given in DOWN messages)\nThe UP notification ( you can use this for both UP \u0026amp; DOWN events ) Setting Value URL https://api.telegram.org/bot1234:BOTTOKEN/sendMessage?chat_id=-987654321\u0026amp; Message {\u0026quot;chat_id\u0026quot;:-987654321,\u0026quot;text\u0026quot;:\u0026quot; \u0026lt;u\u0026gt;\u0026lt;b\u0026gt;UpTimeRbot:\u0026lt;/b\u0026gt;\u0026lt;/u\u0026gt; \u0026lt;a href=\\\u0026quot;*monitorURL*\\\u0026quot;\u0026gt; *monitorFriendlyName* \u0026lt;/a\u0026gt; I status: \u0026lt;b\u0026gt; *alertTypeFriendlyName* \u0026lt;/b\u0026gt; I detail: \u0026lt;code\u0026gt;*alertDetails*\u0026lt;/code\u0026gt; I changed after: *alertDuration* s \u0026quot;,\u0026quot;disable_web_page_preview\u0026quot;:true,\u0026quot;parse_mode\u0026quot;:\u0026quot;HTML\u0026quot;} The DOWN notification Setting Value URL https://api.telegram.org/bot1234:BOTTOKEN/sendMessage?chat_id=-987654321\u0026amp; Message {\u0026quot;chat_id\u0026quot;:-987654321,\u0026quot;text\u0026quot;:\u0026quot; \u0026lt;u\u0026gt;\u0026lt;b\u0026gt;UpTimeRbot:\u0026lt;/b\u0026gt;\u0026lt;/u\u0026gt; \u0026lt;a href=\\\u0026quot;*monitorURL*\\\u0026quot;\u0026gt; *monitorFriendlyName* \u0026lt;/a\u0026gt; I status: \u0026lt;b\u0026gt; *alertTypeFriendlyName* \u0026lt;/b\u0026gt; I detail: \u0026lt;code\u0026gt;*alertDetails*\u0026lt;/code\u0026gt; I \u0026quot;,\u0026quot;disable_web_page_preview\u0026quot;:true,\u0026quot;parse_mode\u0026quot;:\u0026quot;HTML\u0026quot;} ","date":"2021-02-12T13:37:42Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_02_12_send_uptime_robot_notifications_to_telegram_groups_or_howo_to_get_request_anything_via_tg/imgs/uptime_alerts.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_02_12_send_uptime_robot_notifications_to_telegram_groups_or_howo_to_get_request_anything_via_tg/","title":"[HowTo] send Uptime-Robot notifications to Telegram groups or how to GET-request anything via Telegram"},{"content":"Since Registry consumes a lot of data and may be rate limited in the future , you might run your own proxy , but you should secure it properly..\nExample docker-compose.yml\nversion: \u0026#39;3\u0026#39; services: dockerproxy: build: . container_name: ${APP_URL} hostname: ${APP_URL} restart: unless-stopped networks: - default - dockerproxy volumes: - ./apache-block.conf:/etc/apache2/conf.d/apache-block.conf # - ./store.php:/var/www/html/store.php:consistent # - ./wiki/:/var/www/html:consistent ports: - 5000:80 environment: - LETSENCRYPT_EMAIL=${MAIL_ADMINISTRATOR} - LETSENCRYPT_HOST=${APP_URL} - VIRTUAL_HOST=${APP_URL} - VIRTUAL_PORT=80 - VIRTUAL_PROTO=http dockerproxyregistry: image: registry:2.6.2 ##UNCOMMENT THE ABOVE WHEN NO CLIENT SENDS /v1/ anymore # image: registry:2 # build: # context: ./build # dockerfile: Dockerfile-tiddlywiki-php7-nginx-alpine container_name: dockerregistryproxy hostname: dockerregistryproxy restart: unless-stopped networks: - dockerproxy volumes: - /storage_global/machine.hq.mydomain.systems/dockerproxy:/var/lib/registry environment: - GITURL - GITNAME - GITEMAIL - BASICUSER - BASICPASS - REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io - REGISTRY_PROXY_USERNAME=${UPSTREAM_USER} - REGISTRY_PROXY_PASSWORD=${UPSTREAM_PASS} # - REGISTRY_HTTP_SECRET=${HTTPSECRET} networks: dockerproxy: default: external: name: nginx-proxy Example Dockerfile:\nFROM alpine RUN apk add apache2 apache2-proxy bash RUN sed \u0026#39;s/#LoadModule remoteip_module/LoadModule remoteip_module/g\u0026#39; /etc/apache2/httpd.conf -i EXPOSE 80 CMD /usr/sbin/httpd -DFOREGROUND #cmd /bin/bash -c \u0026#34;which apachectl ;which apache ;which apache2 ;sleep 6000\u0026#34; Example Apache-block.conf\n\u0026lt;VirtualHost *:80 \u0026gt; ServerName _default ServerAlias \u0026#34;*\u0026#34; #RemoteIPHeader X-Forwarded-For #RemoteIPHeader X-Client-IP RemoteIPHeader X-Real-IP #RemoteIPHeader X-Forwarded-For RemoteIPTrustedProxy 172.0.0.0 192.168.178.52 ErrorDocument 403 \u0026#34;You are not in my Friend list 403\u0026#34; ErrorDocument 401 \u0026#34;Unauthorized 401\u0026#34; ErrorDocument 404 \u0026#34;Not Found 404\u0026#34; \u0026lt;Location /\u0026gt; Require ip 127.0.0.0/8 192.168.0.0/16 10.12.13.14 10.1.2.1 Require local Require host .mydomain.eu .yourdomain.de .yourdomain.systems .uptimerobot.com nginx.nginx-proxy Require forward-dns myhosta.mydomain.eu myhostb.mydomain.eu \u0026lt;/Location\u0026gt; \u0026lt;Directory /\u0026gt; \u0026lt;Limit GET POST PUT HEAD\u0026gt; Order deny,allow Deny from all Allow from localhost Allow from 24.134.39.209 Allow from 37.120.175.232 Allow from *\\.mydomain.eu Allow from *\\.yourdomain\\.de Allow from *\\.yourdomain\\.systems Allow from 192.168\\.*\\.* Allow from 172\\.15\\.*\\.* Allow from 172\\.16\\.*\\.* Allow from 172\\.17\\.*\\.* Allow from 172\\.18\\.*\\.* Allow from 172\\.19\\.*\\.* Allow from 172\\.2*\\.*\\.* Allow from 127\\.*\\.*\\.* \u0026lt;/Limit\u0026gt; \u0026lt;/Directory\u0026gt; ErrorLog /dev/stderr CustomLog /dev/stdout common LogFormat \u0026#34;%h %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; combined LogFormat \u0026#34;%{X-Forwarded-For}i %l %u %t \\\u0026#34;%r\\\u0026#34; %\u0026gt;s %b \\\u0026#34;%{Referer}i\\\u0026#34; \\\u0026#34;%{User-Agent}i\\\u0026#34;\u0026#34; proxy SetEnvIf X-Forwarded-For \u0026#34;^.*\\..*\\..*\\..*\u0026#34; forwarded CustomLog \u0026#34;logs/access_log\u0026#34; combined env=!forwarded CustomLog \u0026#34;logs/access_log\u0026#34; proxy env=forwarded Header set Host \u0026#34;dockerproxy.hq.kosmoskosmos.systems\u0026#34; Header set \u0026#34;Docker-Distribution-Api-Version\u0026#34; \u0026#34;registry/2.0\u0026#34; RequestHeader set X-Forwarded-Proto \u0026#34;https\u0026#34; ProxyRequests off ProxyPreserveHost on ProxyPass / http://dockerregistryproxy:5000/ ProxyPassReverse / http://dockerregistryproxy:5000/ # \u0026lt;Location /registry\u0026gt; # Order deny,allow # Allow from all # AuthName \u0026#34;Registry Authentication\u0026#34; # AuthType basic # AuthUserFile \u0026#34;/auth/htpasswd\u0026#34; # Require valid-user # \u0026lt;/Location\u0026gt; \u0026lt;/VirtualHost\u0026gt; ","date":"2020-05-12T00:00:00Z","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2020_05_12_running_a_dockerproxy_only_accesible_via_specific_reverse_hosts_or_subnet/","title":"Running a dockerproxy only accesible via specific reverse hosts or subnets"},{"content":"Since SRI(Subresource Integrity)-Checks are used more and more , Hugo also supports this, but unfortunately the space character can become a problem in multi-line template files.\nyou may find your template having a file themes/THEMENAME/data/external.yaml that looks like e.g.\nVibrant: - src: /assets/cdn_jsdelivr_net/npm/node-vibrant_VERSION_3.1.5/dist/vibrant.min.js integrity: sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g= type: script PhotoSwipe: - src: /assets/cdn_jsdelivr_net/npm/photoswipe_VERSION_4.1.3/dist/photoswipe.min.js integrity: sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo= type: script defer: true ... The Problem - no Space between attributes The Problem arising with the renderer not rendering spaces looks like a complain from Firefox no Space between attributes in source code view, or external javascript failing to load ..\nso the resulting html is invalid\n\u0026lt;script integrity=\u0026#34;sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=\u0026#34;src=\u0026#34;/assets/cdn_jsdelivr_net/npm/node-vibrant_VERSION_3.1.5/dist/vibrant.min.js\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; defer=\u0026#34;false\u0026#34; \u0026gt; \u0026lt;/script\u0026gt;\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;/ts/main.js\u0026#34; defer \u0026gt;\u0026lt;/script\u0026gt; ( you clearly see that e.g. the src= part is missing spaces )\nHere the trick was to create the file layouts/partials/helper/external.html and use a \u0026quot; after the {{- with .integrity -}} and leave the tag before \u0026ldquo;unclosed\u0026rdquo;:\n{{- $List := index .Context.Site.Data.external .Namespace -}} {{- with $List -}} {{- range . -}} {{- if eq .type \u0026#34;script\u0026#34; -}} \u0026lt;script src=\u0026#34;{{ .src }}\u0026#34; defer=\u0026#34;{{ default false .defer }} {{- with .integrity -}}\u0026#34; integrity=\u0026#34;{{ . }}\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt; \u0026lt;/script\u0026gt; {{- else -}}\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt; \u0026lt;/script\u0026gt; {{- end -}} {{- else if eq .type \u0026#34;style\u0026#34; -}} \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ .src }} {{- with .integrity -}}\u0026#34; integrity=\u0026#34;{{ . }}\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt; {{- else -}}\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt; {{- end -}} {{- else -}} {{- errorf \u0026#34;Error: unknown external resource type: %s\u0026#34; .type -}} {{- end -}} {{- end -}} {{- else -}} {{- errorf \u0026#34;Error: external resource \u0026#39;%s\u0026#39; is not found\u0026#34; .Namespace -}} {{- end -}} So the renderer does what it should and finally puts the right spaces:\n\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;https://cdn.jsdelivr.net/npm/node-vibrant@3.1.5/dist/vibrant.min.js\u0026#34; defer=\u0026#34;false\u0026#34; integrity=\u0026#34;sha256-5NovOZc4iwiAWTYIFiIM7DxKUXKWvpVEuMEPLzcm5/g=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34; \u0026gt; \u0026lt;/script\u0026gt;\u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;/ts/main.js\u0026#34; defer \u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; ","date":"2020-03-15T00:00:00Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2020_03_15_mastering_hugo_template_whitespaces_on_external_scripts_integrity_tags/imgs/hugospaceOK.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2020_03_15_mastering_hugo_template_whitespaces_on_external_scripts_integrity_tags/","title":"Mastering Hugo template whitespaces on external scripts integrity tags"},{"content":"It\u0026rsquo;s quite easy since Grafana containers already have the respecting parameters you only need 3 files and 1 crontab entry.\nmodify your docker-compose.yml like this\ngrafana-render: hostname: grafana-render image: grafana/grafana-image-renderer:latest ports: - \u0026#34;127.0.0.1:8081:8081\u0026#34; # - ./data/graphite.htpasswd:/etc/nginx/.htpasswd grafana: # image: grafana/grafana:4.2.0 image: grafana/grafana:4.6.5 ports: - \u0026#34;127.0.0.1:3000:3000\u0026#34; volumes: - ./data/grafana:/var/lib/grafana # links: # - graphite environment: - GF_EXTERNAL_IMAGE_STORAGE_PROVIDER=webdav - GF_EXTERNAL_IMAGE_STORAGE_PUBLIC_URL=https://my.domain.lan/grafana-uploads/media - GF_EXTERNAL_IMAGE_STORAGE_PUBLICURL=https://my.domain.lan/grafana-uploads/media - GF_EXTERNAL_IMAGE_STORAGE_WEBDAV_PUBLICURL=https://my.domain.lan/grafana-uploads/media - GF_EXTERNAL_IMAGE_STORAGE_WEBDAV_PUBLIC_URL=https://my.domain.lan/grafana-uploads/media - GF_EXTERNAL_IMAGE_STORAGE_WEBDAV_URL=http://webdav.my.domain.lan/media - GF_EXTERNAL_IMAGE_STORAGE_WEBDAV_USERNAME=grafana - GF_EXTERNAL_IMAGE_STORAGE_WEBDAV_PASSWORD=PassSharedGrafanaWebdav_CHANGE_ME - GF_RENDERING_SERVER_URL=http://grafana-render:8081/render - GF_SERVER_ROOT_URL=https://my.domain.lan - GF_SECURITY_ADMIN_PASSWORD=N0B0dyKnows_You_SHOULD_CHANGE_ME - GF_SMTP_ENABLED=true - GF_SMTP_HOST=smtp.mydomain.lan - GF_SMTP_USER=sensors@mydomain.lan - GF_SMTP_PASSWORD=mySMTP_PASSWORD_You_SHOULD_CHANGE_ME - GF_LOG_FILTERS=rendering:debug restart: unless-stopped webdav.my.domain.lan: restart: unless-stopped hostname: webdav.my.domain.lan container_name: webdav.my.domain.lan build: context: ./ # dockerfile: Dockerfile-alternate dockerfile: Dockerfile.webdav ports: - \u0026#34;127.0.0.1:8008:80\u0026#34; volumes: - \u0026#34;/opt/docker-compose/general/myproject_services/my.domain.lan/uploads/grafana-uploads/:/media\u0026#34; environment: USERNAME: grafana PASSWORD: PassSharedGrafanaWebdav_CHANGE_ME create Dockerfile.webdav\nFROM thefoundation/upgraded-operating-systems:ubuntu-bionic RUN ln -s /usr/share/zoneinfo/Europe/Berlin RUN apt-get update \u0026amp;\u0026amp; apt-get install -y nginx nginx-extras apache2-utils VOLUME /media EXPOSE 80 COPY webdav.conf /etc/nginx/conf.d/default.conf RUN rm /etc/nginx/sites-enabled/* COPY entrypoint-webdav.sh / RUN chmod +x entrypoint-webdav.sh CMD /entrypoint-webdav.sh \u0026amp;\u0026amp; nginx -g \u0026#34;daemon off;\u0026#34; create entrypoint-webdav.sh\n#!/bin/bash if [[ -n \u0026#34;$USERNAME\u0026#34; ]] \u0026amp;\u0026amp; [[ -n \u0026#34;$PASSWORD\u0026#34; ]] then htpasswd -bc /etc/nginx/htpasswd $USERNAME $PASSWORD echo Done. else echo Using no auth. sed -i \u0026#39;s%auth_basic \u0026#34;Restricted\u0026#34;;% %g\u0026#39; /etc/nginx/conf.d/default.conf sed -i \u0026#39;s%auth_basic_user_file htpasswd;% %g\u0026#39; /etc/nginx/conf.d/default.conf find the folder of your webdav-images ( docker-compose config ) and add a cron entry\n#Grafana webDAV cleanup 15 */2 * * * find /opt/docker-compose/general/my_services/my.grafana.lan/uploads/grafana-uploads/media -type f -name \u0026#34;*.png\u0026#34; -mtime +2 -delete \u0026amp;\u0026gt;/dev/null || true setup your grafana to include the images\nhave fun ","date":"2019-06-23T23:50:42Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2019_06_23_adding_webdav_to_docker_grafana_for_image_previews/imgs/graf_prev.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2019_06_23_adding_webdav_to_docker_grafana_for_image_previews/","title":"Adding webdav to docker-compose grafana stack for image previews"},{"content":" in your config ( here with toml ) , change : [[collections.fields]] key = \u0026#34;pubdate\u0026#34; title = \u0026#34;Pub Date\u0026#34; type = \u0026#34;date\u0026#34; default = \u0026#34;now\u0026#34; to look like this: [[collections.fields]] key = \u0026#34;pubdate\u0026#34; title = \u0026#34;Pub Date\u0026#34; type = \u0026#34;date\u0026#34; default = \u0026#34;now\u0026#34; [[collections.fields]] key = \u0026#34;tags\u0026#34; title = \u0026#34;Tags\u0026#34; type = \u0026#34;chips\u0026#34; Result: regards :) ","date":"2019-04-13T13:23:42Z","image":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_04_13_hokus_cms_for_hugo_tags_in_post_editor/imgs/hokustaggs.png","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/2021_04_13_hokus_cms_for_hugo_tags_in_post_editor/","title":"Hokus CMS for Hugo - Tags in Post Editor"},{"content":" alternatives: http://www.myvideo.de/musik/kate-nash/foundations-video-m-4610518 https://de.screen.yahoo.com/musik/foundations-044634217.html Test 1 Test 2 Test 3 Test 4 Test 5 Test 6 Test 7 Test 8 Test 9 Test 10 Test 11 Test 12 Test 13 Test 14 Test 15 Test 16 Test 17 Test 18 Test 19 Test 20 Test 21 Test 22 Test 23 ","date":"2007-06-18T13:37:42Z","image":"/assets/i_ytimg_com/vi_webp/ryH5cga0yUI/sddefault.webp","permalink":"https://the-foundation.is-a-p.ro.eu.org/posts/0000_soundtrack/","title":"( Soundtrack from Kate nash )"}]